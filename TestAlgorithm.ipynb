{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T19:07:43.368646Z",
     "start_time": "2025-04-28T19:07:43.360718Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:08:51.796528Z",
     "start_time": "2025-04-28T19:07:47.815944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Пути\n",
    "people_dir = 'all_images'  # <-- замени на путь к папке с фото людей\n",
    "\n",
    "# Константы\n",
    "IMG_SIZE = 300\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "            img_array = image.img_to_array(img)\n",
    "            images.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке изображения {filename}: {e}. Пропускаем файл.\")\n",
    "            continue\n",
    "    labels = np.full(len(images), label)  # создаём массив меток\n",
    "    return np.array(images, dtype=np.float32), labels  # <-- ВАЖНО: возвращаем np.array!\n",
    "\n",
    "# Загрузка фотографий людей\n",
    "people_images, people_labels = load_images_from_folder(people_dir, label=1)"
   ],
   "id": "529dbd4e04310cd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при загрузке изображения .DS_Store: cannot identify image file <_io.BytesIO object at 0x14921d2b0>. Пропускаем файл.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:05.557906Z",
     "start_time": "2025-04-28T19:09:05.482301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "people_images_2 = people_images[:300]\n",
    "people_labels_2 = people_labels[:300]"
   ],
   "id": "e1bda54b1404e435",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:08.222623Z",
     "start_time": "2025-04-28T19:09:06.981503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Генерация искусственных \"пустых\" изображений\n",
    "num_fake = people_images_2.shape[0]\n",
    "fake_images = np.random.rand(num_fake, IMG_SIZE, IMG_SIZE, 3).astype(np.float32) * 255.0  # Приводим к тому же диапазону\n",
    "\n",
    "fake_labels = np.zeros(num_fake, dtype=np.int32)"
   ],
   "id": "1301ee69e0a731f0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:12.659291Z",
     "start_time": "2025-04-28T19:09:09.834231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Склейка всех данных\n",
    "all_images = np.concatenate([people_images_2, fake_images], axis=0) / 255.0  # Нормализация сразу после склейки\n",
    "all_labels = np.concatenate([people_labels_2, fake_labels], axis=0)"
   ],
   "id": "6868133cd1d24851",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:14.592287Z",
     "start_time": "2025-04-28T19:09:13.704038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Перемешиваем данные\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels)"
   ],
   "id": "9cf2d9900d5c2676",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:16.619369Z",
     "start_time": "2025-04-28T19:09:15.755113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создание tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1000).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE)"
   ],
   "id": "6dbf339679ccbab0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:19.437205Z",
     "start_time": "2025-04-28T19:09:18.068288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Построение модели\n",
    "base_model = EfficientNetB3(\n",
    "    weights='efficientnetb3_notop.h5',  # путь к локальному файлу\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False"
   ],
   "id": "fac130ede6801369",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:21.560195Z",
     "start_time": "2025-04-28T19:09:21.544664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)"
   ],
   "id": "1a2e0e6f37443ddf",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:24.756489Z",
     "start_time": "2025-04-28T19:09:24.731594Z"
    }
   },
   "cell_type": "code",
   "source": "model = Model(inputs=base_model.input, outputs=outputs)",
   "id": "495962b89ed597ca",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:09:25.895653Z",
     "start_time": "2025-04-28T19:09:25.871485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Компиляция\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "a9606597aa8a8c76",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:17:46.739485Z",
     "start_time": "2025-04-28T19:09:26.793465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обучение\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ],
   "id": "cf323aadadae3f38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m60s\u001B[0m 4s/step - accuracy: 0.5139 - loss: 0.7079 - val_accuracy: 0.5000 - val_loss: 0.6574\n",
      "Epoch 2/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 3s/step - accuracy: 0.5334 - loss: 0.7002 - val_accuracy: 0.5000 - val_loss: 0.7059\n",
      "Epoch 3/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m50s\u001B[0m 3s/step - accuracy: 0.5630 - loss: 0.6716 - val_accuracy: 1.0000 - val_loss: 0.6085\n",
      "Epoch 4/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 3s/step - accuracy: 0.7433 - loss: 0.6184 - val_accuracy: 1.0000 - val_loss: 0.5814\n",
      "Epoch 5/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 3s/step - accuracy: 0.7616 - loss: 0.6149 - val_accuracy: 0.9917 - val_loss: 0.5557\n",
      "Epoch 6/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m50s\u001B[0m 3s/step - accuracy: 0.7026 - loss: 0.6210 - val_accuracy: 1.0000 - val_loss: 0.5615\n",
      "Epoch 7/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 3s/step - accuracy: 0.8042 - loss: 0.5937 - val_accuracy: 0.5000 - val_loss: 0.5732\n",
      "Epoch 8/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 3s/step - accuracy: 0.7673 - loss: 0.5655 - val_accuracy: 1.0000 - val_loss: 0.5021\n",
      "Epoch 9/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 3s/step - accuracy: 0.7858 - loss: 0.5458 - val_accuracy: 1.0000 - val_loss: 0.4596\n",
      "Epoch 10/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 3s/step - accuracy: 0.8062 - loss: 0.5129 - val_accuracy: 0.5000 - val_loss: 0.5901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14a332e10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:17:54.331826Z",
     "start_time": "2025-04-28T19:17:54.264021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (Опционально) Разморозка части EfficientNetB3\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 400\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "c1583f7ad14354c6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:26:12.070848Z",
     "start_time": "2025-04-28T19:17:55.316288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ],
   "id": "9739d8a6528fda96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 3s/step - accuracy: 0.8398 - loss: 0.4878 - val_accuracy: 1.0000 - val_loss: 0.4418\n",
      "Epoch 2/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m50s\u001B[0m 3s/step - accuracy: 0.8427 - loss: 0.4897 - val_accuracy: 0.9917 - val_loss: 0.4901\n",
      "Epoch 3/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 3s/step - accuracy: 0.8503 - loss: 0.4740 - val_accuracy: 1.0000 - val_loss: 0.4739\n",
      "Epoch 4/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 3s/step - accuracy: 0.8494 - loss: 0.4698 - val_accuracy: 1.0000 - val_loss: 0.4461\n",
      "Epoch 5/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 3s/step - accuracy: 0.8184 - loss: 0.5004 - val_accuracy: 1.0000 - val_loss: 0.4685\n",
      "Epoch 6/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 3s/step - accuracy: 0.7941 - loss: 0.5077 - val_accuracy: 1.0000 - val_loss: 0.4670\n",
      "Epoch 7/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 3s/step - accuracy: 0.8319 - loss: 0.4912 - val_accuracy: 1.0000 - val_loss: 0.4738\n",
      "Epoch 8/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 3s/step - accuracy: 0.8364 - loss: 0.4697 - val_accuracy: 1.0000 - val_loss: 0.4463\n",
      "Epoch 9/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 4s/step - accuracy: 0.8424 - loss: 0.4834 - val_accuracy: 1.0000 - val_loss: 0.4571\n",
      "Epoch 10/10\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m50s\u001B[0m 3s/step - accuracy: 0.8614 - loss: 0.4633 - val_accuracy: 1.0000 - val_loss: 0.4378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14ca12590>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:26:56.149827Z",
     "start_time": "2025-04-28T19:26:55.777302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Сохранение модели\n",
    "model.save('efficientnetb3_people_detector_2.h5')"
   ],
   "id": "ef58655e89af2f2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Тестирование",
   "id": "ed377998972476e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:28:40.044086Z",
     "start_time": "2025-04-28T19:28:38.511810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка обученной модели\n",
    "model = tf.keras.models.load_model('efficientnetb3_people_detector_2.h5')\n",
    "\n",
    "# Путь к тестовым картинкам\n",
    "test_dir = 'test'\n",
    "\n",
    "# Функция для предсказания\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # модель ожидает batch\n",
    "    \n",
    "    prediction = model.predict(img_array)[0][0]  # результат между 0 и 1\n",
    "    if prediction > 0.5:\n",
    "        print(f\"{os.path.basename(img_path)}: Человек найден ({prediction:.2f})\")\n",
    "    else:\n",
    "        print(f\"{os.path.basename(img_path)}: Человека нет ({prediction:.2f})\")"
   ],
   "id": "8c9db012d1f15ccd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T19:30:40.903Z",
     "start_time": "2025-04-28T19:30:39.922086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Проверяем все тестовые картинки\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(test_dir, filename)\n",
    "        predict_image(img_path)"
   ],
   "id": "3c6be49b34bcd017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 136ms/step\n",
      "IMG_8288.jpg: Человек найден (0.59)\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 209ms/step\n",
      "IMG_8289.jpg: Человек найден (0.72)\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 122ms/step\n",
      "8cf3b758d6af4abbaebc1b7bef7f4855.max-2500x1500.jpg: Человек найден (0.72)\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 110ms/step\n",
      "IMG_8290.jpg: Человек найден (0.73)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a75f670c6d77ff07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
